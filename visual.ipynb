{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from torchviz import make_dot\n",
    "nodes = torch.randint(0, 1000, (1, 5))  # Example batch of 1, with 5 nodes\n",
    "edges = torch.tensor([[0, 1], [1, 2], [2, 3], [3, 4]])  # Example edges (pairs of nodes)\n",
    "types = torch.tensor([0, 1, 0, 1])  # Example edge types\n",
    "model = GraphEncoder(node_vocab_size=1000, relation_vocab_size=500, gnn_layers=3, embedding_size=128, node_embedding_dim=256)\n",
    "output = model(nodes, edges, types)\n",
    "dot = make_dot(output, params=dict(model.named_parameters()))\n",
    "dot.render(\"graph_encoder\", format=\"png\")  # Save as a PNG image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GraphEncoder(nn.Module):\n",
    "    def __init__(self, num_nodes, num_relations, gnn_layers, embedding_size, initilized_embedding, dropout_ratio=0.3):\n",
    "        super(GraphEncoder, self).__init__()\n",
    "        self.num_nodes = num_nodes\n",
    "        self.num_relations = num_relations\n",
    "        self.gnn_layers = gnn_layers\n",
    "        self.embedding_size = embedding_size\n",
    "        self.dropout_ratio = dropout_ratio\n",
    "\n",
    "        self.node_embedding = nn.Embedding(num_nodes, embedding_size)\n",
    "        self.node_embedding.from_pretrained(torch.from_numpy(np.load(initilized_embedding)), freeze=False)\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout_ratio)\n",
    "\n",
    "        self.gnn = []\n",
    "        for layer in range(gnn_layers):\n",
    "            self.gnn.append(RGCNConv(embedding_size, embedding_size,num_relations=num_relations))  # if rgcn is too slow, you can use gcn\n",
    "        self.gnn = ListModule(*self.gnn)\n",
    "\n",
    "    def forward(self, nodes, edges, types):\n",
    "        \"\"\"\n",
    "        :param nodes: Tensor, shape [batch_size, num_nodes]\n",
    "        :param edges: List[List[edge_idx]], where each edge_idx is [2, num_edges]\n",
    "        :param types: List[List[edge_types]], where each edge_types is [num_edges]\n",
    "        \"\"\"\n",
    "        batch_size = nodes.size(0)\n",
    "        device = nodes.device\n",
    "\n",
    "        # (batch_size, num_nodes, output_size)\n",
    "        node_embeddings = []\n",
    "        for bid in range(batch_size):\n",
    "            # Convert edges and types to tensors\n",
    "            edge_index = torch.tensor(edges[bid], dtype=torch.long, device=device)  # Shape: [2, num_edges]\n",
    "            edge_type = torch.tensor(types[bid], dtype=torch.long, device=device)  # Shape: [num_edges]\n",
    "\n",
    "            embed = self.node_embedding(nodes[bid, :])\n",
    "\n",
    "            for lidx, rgcn in enumerate(self.gnn):\n",
    "                if lidx == len(self.gnn) - 1:\n",
    "                    embed = rgcn(embed, edge_index=edge_index, edge_type=edge_type)\n",
    "                else:\n",
    "                    embed = self.dropout(F.relu(rgcn(embed, edge_index=edge_index, edge_type=edge_type)))\n",
    "\n",
    "            node_embeddings.append(embed)\n",
    "\n",
    "        node_embeddings = torch.stack(node_embeddings, 0)  # [batch_size, num_node, embedding_size]\n",
    "        return node_embeddings"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
